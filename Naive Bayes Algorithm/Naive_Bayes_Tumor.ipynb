{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code for applying Naive bayes's Algorithm on Tumor Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Understanding naive bayes algorithm first we need to Understand what is bayes theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets say we have two events event A and B calculating the conditional probability for both of them are\n",
    "\n",
    "Equation 1 and  2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(A|B) = \\frac{P(B \\cap A)}{P(B)}           \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(B|A) = \\frac{P(A \\cap B)}{P(A)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we know ,\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(A \\cap B) = P(B \\cap A)\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    " P(A \\cap B) = P(B|A)*P(A) \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(B \\cap A) = P(A|B)*P(B) \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "equating both of them we get Bayes rule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(A|B) = \\frac{P(B|A)P(A)}{P(B)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Naive Bayes algorithm we try to find the posterior probability for each class label and whose prosterior probability will be maximum among all labels we will say that the tumor belongs to that class or label .Lets see what do i mean by posterior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "P(A|B) is Posterior probability and P(B|A) is liklihood Probability and P(A) is prior probabilty for calculating posterior probabilty we only need to calculate two probabilities that are liklihood and prior other probabilities can be calculated using these.<br>\n",
    "How do we start with the Algorithm??<br>\n",
    "For that first we convert our data into three parts that is<br>\n",
    "- Training Data(70% part to the entire data)<br>\n",
    "- Cross validation Data(10% part to the entire data)<br>\n",
    "- Testing Data(20% part to the entire data)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets assume we have two features radius_mean and texture_mean and the class labels are M(melignant),B(beningn) that is binomial so we need to calculate prosterior probabilty for class M and B<br>\n",
    "How can we calculate that when we have two features in account<br>\n",
    "understand this using an example ,<br>\n",
    "we always have features for an example and we try to calculate the probability of class on a condition features(feature vector)<br>\n",
    "consider one example(Tumor) having radius_mean= __x__ and texture_mean = __y__<br>\n",
    "so our posterior probability for both the classes given the features are,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(diag=B|radius\\_mean=x \\cap texture\\_mean=y) = \\frac{P(radius\\_mean=x \\cap texture\\_mean=y|diag=B)*P(B)}{P(radius\\_mean=x \\cap texture\\_mean=y|diag=B)*P(B)+P(radius\\_mean = x \\cap texture\\_mean=y|diag=M)*P(M)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "P(diag=M|radius\\_mean=x \\cap texture\\_mean=y) = \\frac{P(radius\\_mean=x \\cap texture\\_mean=y|diag=M)*P(M)}{P(radius\\_mean=x \\cap texture\\_mean=y|diag=B)*P(B)+P(radius\\_mean = x \\cap texture\\_mean=y|diag=M)*P(M)}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as we have written the posterior probability formula for both the classes now out of these two posterior probability for which class is bigger in magnitude means that when we have feature values x and y it belongs to that class\n",
    "in other words<br>if\n",
    "\\begin{equation}\n",
    "P(diag=B|radius\\_mean=x \\cap texture\\_mean=y) > P(diag=M|radius\\_mean=x \\cap texture\\_mean=y)\n",
    "\\end{equation}\n",
    "\n",
    "then our __Tumor belongs to B class__\n",
    "\n",
    "and if\n",
    "\\begin{equation}\n",
    "P(diag=M|radius\\_mean=x \\cap texture\\_mean=y) > P(diag=B|radius\\_mean=x \\cap texture\\_mean=y)\n",
    "\\end{equation}\n",
    "Then our __Tumor belongs to  M class__ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But How to calculate liklihood probability and prior probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prior Probability is easier to calculate <br>\n",
    "prior probabilty of B is (frequency of tumor having class __B__ in training data)/total no of training examples<br>\n",
    "\\begin{equation}\n",
    "P(diag=B) = \\frac{\\text{Frequency of B in training data} }{\\text{Total training examples}}\n",
    "\\end{equation}\n",
    "\n",
    "prior probabilty of M is (frequency of tumor having class __M__ in training data)/total no of training examples<br>\n",
    "\\begin{equation}\n",
    "P(diag=M) = \\frac{\\text{Frequency of M in training data} }{\\text{Total training examples}}\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For liklihood probability for __B__ we need to calculate\n",
    "\\begin{equation}\n",
    "P(radius\\_mean=x \\cap texture\\_mean=y|diag=B)\n",
    "\\end{equation}\n",
    "<br>\n",
    "We called this algorithm as NAIVE its because we have taken a naive assumption that all of our features are independent to each other, so the upper equation can be written as<br>\n",
    "\\begin{equation}\n",
    "P(radius\\_mean=x |diag=B) * P(texture\\_mean=y|diag=B)\n",
    "\\end{equation}\n",
    "now,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as s\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"Tumor_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean\n",
       "0         M        17.99         10.38          122.80\n",
       "1         M        20.57         17.77          132.90\n",
       "2         M        19.69         21.25          130.00\n",
       "3         M        11.42         20.38           77.58\n",
       "4         M        20.29         14.34          135.10"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.iloc[:,1:5]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enter the parameters by which you wanted to divide your data\n",
    "Train_per=70\n",
    "Cross_per=10\n",
    "Test_per=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dividing the data into 3 parts\n",
    "Training_data=data.iloc[:int((Train_per/100)*len(data))]\n",
    "Cross_validation_data=data.iloc[int((Train_per/100)*len(data)):int(((Train_per+Cross_per)/100)*len(data))]\n",
    "Testing_data=data.iloc[int(((Train_per+Cross_per)/100)*len(data)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean\n",
       "0         M        17.99         10.38          122.80\n",
       "1         M        20.57         17.77          132.90\n",
       "2         M        19.69         21.25          130.00\n",
       "3         M        11.42         20.38           77.58\n",
       "4         M        20.29         14.34          135.10"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x2a009536be0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the scatter plot beteen the two features \n",
    "plt.scatter(Training_data[\"radius_mean\"],Training_data[\"texture_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>B</td>\n",
       "      <td>11.06</td>\n",
       "      <td>14.83</td>\n",
       "      <td>70.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>B</td>\n",
       "      <td>11.80</td>\n",
       "      <td>17.26</td>\n",
       "      <td>75.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>M</td>\n",
       "      <td>17.91</td>\n",
       "      <td>21.02</td>\n",
       "      <td>124.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>B</td>\n",
       "      <td>11.93</td>\n",
       "      <td>10.91</td>\n",
       "      <td>76.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>B</td>\n",
       "      <td>12.96</td>\n",
       "      <td>18.29</td>\n",
       "      <td>84.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean\n",
       "398         B        11.06         14.83           70.31\n",
       "399         B        11.80         17.26           75.26\n",
       "400         M        17.91         21.02          124.40\n",
       "401         B        11.93         10.91           76.14\n",
       "402         B        12.96         18.29           84.18"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cross_validation_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>B</td>\n",
       "      <td>13.380</td>\n",
       "      <td>30.72</td>\n",
       "      <td>86.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>B</td>\n",
       "      <td>11.630</td>\n",
       "      <td>29.29</td>\n",
       "      <td>74.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>B</td>\n",
       "      <td>13.210</td>\n",
       "      <td>25.25</td>\n",
       "      <td>84.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>B</td>\n",
       "      <td>13.000</td>\n",
       "      <td>25.13</td>\n",
       "      <td>82.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>B</td>\n",
       "      <td>9.755</td>\n",
       "      <td>28.20</td>\n",
       "      <td>61.68</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    diagnosis  radius_mean  texture_mean  perimeter_mean\n",
       "455         B       13.380         30.72           86.34\n",
       "456         B       11.630         29.29           74.87\n",
       "457         B       13.210         25.25           84.10\n",
       "458         B       13.000         25.13           82.61\n",
       "459         B        9.755         28.20           61.68"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#differentaiting data class wise so that we can calculatetheir liklihood or prior probabilities\n",
    "B_Training_data = Training_data[Training_data[\"diagnosis\"] == \"B\"]\n",
    "M_Training_data = Training_data[Training_data[\"diagnosis\"] == \"M\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>B</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>B</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean\n",
       "19         B       13.540         14.36           87.46\n",
       "20         B       13.080         15.71           85.63\n",
       "21         B        9.504         12.44           60.34\n",
       "37         B       13.030         18.42           82.61\n",
       "46         B        8.196         16.84           51.71"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_Training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  diagnosis  radius_mean  texture_mean  perimeter_mean\n",
       "0         M        17.99         10.38          122.80\n",
       "1         M        20.57         17.77          132.90\n",
       "2         M        19.69         21.25          130.00\n",
       "3         M        11.42         20.38           77.58\n",
       "4         M        20.29         14.34          135.10"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "M_Training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prior Probabilities of both B and M are--- 0.5653266331658291 0.43467336683417085\n"
     ]
    }
   ],
   "source": [
    "#prior probabilities \n",
    "P_diagnosis_B = B_Training_data.shape[0]/Training_data.shape[0]\n",
    "P_diagnosis_M = M_Training_data.shape[0]/Training_data.shape[0]\n",
    "print(\"Prior Probabilities of both B and M are---\",P_diagnosis_B,P_diagnosis_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population parameters for B  [12.07644    17.12715556 77.58168889] [[  2.9974523    0.20174291  19.73035849]\n",
      " [  0.20174291  11.2881258    1.53650259]\n",
      " [ 19.73035849   1.53650259 130.8106891 ]]\n",
      "Population parameters for M  [ 17.27416185  21.36098266 114.02965318] [[ 10.33747676   1.39954879  70.03339448]\n",
      " [  1.39954879  14.40388101   9.61636604]\n",
      " [ 70.03339448   9.61636604 478.85535569]]\n"
     ]
    }
   ],
   "source": [
    "#calculating the parameters which are required to calculate the liklihood probabilities because the are calculating\n",
    "#using pdf and pdf requires the values of these parameters\n",
    "#why mu_ because we are dealing with samples so we need to calculate best population param using samples bye MLE\n",
    "mu_cap_B = np.array(B_Training_data.mean())\n",
    "cov_B = np.array(B_Training_data.cov())\n",
    "mu_cap_M = np.array(M_Training_data.mean())\n",
    "cov_M = np.array(M_Training_data.cov())\n",
    "print(\"Population parameters for B \",mu_cap_B,cov_B)\n",
    "print(\"Population parameters for M \",mu_cap_M,cov_M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>B</td>\n",
       "      <td>13.540</td>\n",
       "      <td>14.36</td>\n",
       "      <td>87.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>B</td>\n",
       "      <td>13.080</td>\n",
       "      <td>15.71</td>\n",
       "      <td>85.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>B</td>\n",
       "      <td>9.504</td>\n",
       "      <td>12.44</td>\n",
       "      <td>60.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>B</td>\n",
       "      <td>13.030</td>\n",
       "      <td>18.42</td>\n",
       "      <td>82.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>B</td>\n",
       "      <td>8.196</td>\n",
       "      <td>16.84</td>\n",
       "      <td>51.71</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   diagnosis  radius_mean  texture_mean  perimeter_mean\n",
       "19         B       13.540         14.36           87.46\n",
       "20         B       13.080         15.71           85.63\n",
       "21         B        9.504         12.44           60.34\n",
       "37         B       13.030         18.42           82.61\n",
       "46         B        8.196         16.84           51.71"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_Training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>2.997452</td>\n",
       "      <td>0.201743</td>\n",
       "      <td>19.730358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.201743</td>\n",
       "      <td>11.288126</td>\n",
       "      <td>1.536503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>19.730358</td>\n",
       "      <td>1.536503</td>\n",
       "      <td>130.810689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                radius_mean  texture_mean  perimeter_mean\n",
       "radius_mean        2.997452      0.201743       19.730358\n",
       "texture_mean       0.201743     11.288126        1.536503\n",
       "perimeter_mean    19.730358      1.536503      130.810689"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_dem = B_Training_data.cov()\n",
    "cov_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>radius_mean</th>\n",
       "      <td>2.997452</td>\n",
       "      <td>0.201743</td>\n",
       "      <td>19.730358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>texture_mean</th>\n",
       "      <td>0.201743</td>\n",
       "      <td>11.288126</td>\n",
       "      <td>1.536503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>perimeter_mean</th>\n",
       "      <td>19.730358</td>\n",
       "      <td>1.536503</td>\n",
       "      <td>130.810689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                radius_mean  texture_mean  perimeter_mean\n",
       "radius_mean        2.997452      0.201743       19.730358\n",
       "texture_mean       0.201743     11.288126        1.536503\n",
       "perimeter_mean    19.730358      1.536503      130.810689"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cov_dem = B_Training_data.iloc[:,1:].cov()\n",
    "cov_dem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31.570887623640477"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking the determinant is zero or not if zero or close to zero then our covariance matrix is singularr and our algo wont work furthur on\n",
    "np.linalg.det(cov_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Function which calculates the posterior probabilities for every class__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Always keep in mind that its not compulsary to always use s.multivariate_normal.pdf it completely depends on data if our data is binomial then we use pdf for  binomial distribution and calculates parameters for that here we are dealing with normal data having more than one type of random variable thats why we are using Multivariate Normal PDF__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predicated_category(x):\n",
    "    B_liklihood = s.multivariate_normal.pdf(x,mu_cap_B,cov_B)*P_diagnosis_B\n",
    "    M_liklihood = s.multivariate_normal.pdf(x,mu_cap_M,cov_M)*P_diagnosis_M\n",
    "    \n",
    "    B_posterior_probability = B_liklihood/(B_liklihood+M_liklihood)\n",
    "    return (1-B_posterior_probability)   #it will return the posterior probability for melignant tumor as we have donr 1-B_posterior_prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>398</th>\n",
       "      <td>11.060</td>\n",
       "      <td>14.83</td>\n",
       "      <td>70.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>11.800</td>\n",
       "      <td>17.26</td>\n",
       "      <td>75.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>17.910</td>\n",
       "      <td>21.02</td>\n",
       "      <td>124.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>11.930</td>\n",
       "      <td>10.91</td>\n",
       "      <td>76.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>12.960</td>\n",
       "      <td>18.29</td>\n",
       "      <td>84.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>12.940</td>\n",
       "      <td>16.17</td>\n",
       "      <td>83.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>12.340</td>\n",
       "      <td>14.95</td>\n",
       "      <td>78.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>10.940</td>\n",
       "      <td>18.59</td>\n",
       "      <td>70.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>16.140</td>\n",
       "      <td>14.86</td>\n",
       "      <td>104.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>12.850</td>\n",
       "      <td>21.37</td>\n",
       "      <td>82.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>17.990</td>\n",
       "      <td>20.66</td>\n",
       "      <td>117.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>12.270</td>\n",
       "      <td>17.92</td>\n",
       "      <td>78.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>11.360</td>\n",
       "      <td>17.57</td>\n",
       "      <td>72.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>11.040</td>\n",
       "      <td>16.83</td>\n",
       "      <td>70.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>412</th>\n",
       "      <td>9.397</td>\n",
       "      <td>21.68</td>\n",
       "      <td>59.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>14.990</td>\n",
       "      <td>22.11</td>\n",
       "      <td>97.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>414</th>\n",
       "      <td>15.130</td>\n",
       "      <td>29.81</td>\n",
       "      <td>96.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>11.890</td>\n",
       "      <td>21.17</td>\n",
       "      <td>76.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>9.405</td>\n",
       "      <td>21.70</td>\n",
       "      <td>59.60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>15.500</td>\n",
       "      <td>21.08</td>\n",
       "      <td>102.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>12.700</td>\n",
       "      <td>12.17</td>\n",
       "      <td>80.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>11.160</td>\n",
       "      <td>21.41</td>\n",
       "      <td>70.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>11.570</td>\n",
       "      <td>19.04</td>\n",
       "      <td>74.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>14.690</td>\n",
       "      <td>13.98</td>\n",
       "      <td>98.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>11.610</td>\n",
       "      <td>16.02</td>\n",
       "      <td>75.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>13.660</td>\n",
       "      <td>19.13</td>\n",
       "      <td>89.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>9.742</td>\n",
       "      <td>19.12</td>\n",
       "      <td>61.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>10.030</td>\n",
       "      <td>21.28</td>\n",
       "      <td>63.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>426</th>\n",
       "      <td>10.480</td>\n",
       "      <td>14.98</td>\n",
       "      <td>67.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>10.800</td>\n",
       "      <td>21.98</td>\n",
       "      <td>68.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>11.130</td>\n",
       "      <td>16.62</td>\n",
       "      <td>70.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>12.720</td>\n",
       "      <td>17.67</td>\n",
       "      <td>80.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>14.900</td>\n",
       "      <td>22.53</td>\n",
       "      <td>102.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>431</th>\n",
       "      <td>12.400</td>\n",
       "      <td>17.68</td>\n",
       "      <td>81.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>20.180</td>\n",
       "      <td>19.54</td>\n",
       "      <td>133.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>18.820</td>\n",
       "      <td>21.97</td>\n",
       "      <td>123.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>434</th>\n",
       "      <td>14.860</td>\n",
       "      <td>16.94</td>\n",
       "      <td>94.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>13.980</td>\n",
       "      <td>19.62</td>\n",
       "      <td>91.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>436</th>\n",
       "      <td>12.870</td>\n",
       "      <td>19.54</td>\n",
       "      <td>82.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>437</th>\n",
       "      <td>14.040</td>\n",
       "      <td>15.98</td>\n",
       "      <td>89.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>438</th>\n",
       "      <td>13.850</td>\n",
       "      <td>19.60</td>\n",
       "      <td>88.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>439</th>\n",
       "      <td>14.020</td>\n",
       "      <td>15.66</td>\n",
       "      <td>89.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>10.970</td>\n",
       "      <td>17.20</td>\n",
       "      <td>71.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441</th>\n",
       "      <td>17.270</td>\n",
       "      <td>25.42</td>\n",
       "      <td>112.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>13.780</td>\n",
       "      <td>15.79</td>\n",
       "      <td>88.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>10.570</td>\n",
       "      <td>18.32</td>\n",
       "      <td>66.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>18.030</td>\n",
       "      <td>16.85</td>\n",
       "      <td>117.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>11.990</td>\n",
       "      <td>24.89</td>\n",
       "      <td>77.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>17.750</td>\n",
       "      <td>28.03</td>\n",
       "      <td>117.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>14.800</td>\n",
       "      <td>17.66</td>\n",
       "      <td>95.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>448</th>\n",
       "      <td>14.530</td>\n",
       "      <td>19.34</td>\n",
       "      <td>94.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>21.100</td>\n",
       "      <td>20.52</td>\n",
       "      <td>138.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>11.870</td>\n",
       "      <td>21.54</td>\n",
       "      <td>76.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>19.590</td>\n",
       "      <td>25.00</td>\n",
       "      <td>127.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>12.000</td>\n",
       "      <td>28.23</td>\n",
       "      <td>76.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>14.530</td>\n",
       "      <td>13.98</td>\n",
       "      <td>93.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>12.620</td>\n",
       "      <td>17.15</td>\n",
       "      <td>80.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     radius_mean  texture_mean  perimeter_mean\n",
       "398       11.060         14.83           70.31\n",
       "399       11.800         17.26           75.26\n",
       "400       17.910         21.02          124.40\n",
       "401       11.930         10.91           76.14\n",
       "402       12.960         18.29           84.18\n",
       "403       12.940         16.17           83.18\n",
       "404       12.340         14.95           78.29\n",
       "405       10.940         18.59           70.39\n",
       "406       16.140         14.86          104.30\n",
       "407       12.850         21.37           82.63\n",
       "408       17.990         20.66          117.80\n",
       "409       12.270         17.92           78.41\n",
       "410       11.360         17.57           72.49\n",
       "411       11.040         16.83           70.92\n",
       "412        9.397         21.68           59.75\n",
       "413       14.990         22.11           97.53\n",
       "414       15.130         29.81           96.71\n",
       "415       11.890         21.17           76.39\n",
       "416        9.405         21.70           59.60\n",
       "417       15.500         21.08          102.90\n",
       "418       12.700         12.17           80.88\n",
       "419       11.160         21.41           70.95\n",
       "420       11.570         19.04           74.20\n",
       "421       14.690         13.98           98.22\n",
       "422       11.610         16.02           75.46\n",
       "423       13.660         19.13           89.46\n",
       "424        9.742         19.12           61.93\n",
       "425       10.030         21.28           63.19\n",
       "426       10.480         14.98           67.49\n",
       "427       10.800         21.98           68.79\n",
       "428       11.130         16.62           70.47\n",
       "429       12.720         17.67           80.98\n",
       "430       14.900         22.53          102.10\n",
       "431       12.400         17.68           81.47\n",
       "432       20.180         19.54          133.80\n",
       "433       18.820         21.97          123.70\n",
       "434       14.860         16.94           94.89\n",
       "435       13.980         19.62           91.12\n",
       "436       12.870         19.54           82.67\n",
       "437       14.040         15.98           89.78\n",
       "438       13.850         19.60           88.68\n",
       "439       14.020         15.66           89.59\n",
       "440       10.970         17.20           71.73\n",
       "441       17.270         25.42          112.40\n",
       "442       13.780         15.79           88.37\n",
       "443       10.570         18.32           66.82\n",
       "444       18.030         16.85          117.50\n",
       "445       11.990         24.89           77.61\n",
       "446       17.750         28.03          117.30\n",
       "447       14.800         17.66           95.88\n",
       "448       14.530         19.34           94.25\n",
       "449       21.100         20.52          138.10\n",
       "450       11.870         21.54           76.83\n",
       "451       19.590         25.00          127.70\n",
       "452       12.000         28.23           76.77\n",
       "453       14.530         13.98           93.86\n",
       "454       12.620         17.15           80.62"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Cross_validation_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior_probability_m = predicated_category(Cross_validation_data.iloc[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_mask_predicted_cross = posterior_probability_m>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "boolean_mask_predicted_cross = np.uint(boolean_mask_predicted_cross)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0], dtype=uint32)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_mask_predicted_cross"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_class=Cross_validation_data[\"diagnosis\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DELL\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:6586: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "cross_val_class.replace(to_replace=[\"M\",\"B\"],value=[1,0],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_class = np.array(cross_val_class)\n",
    "cross_val_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9298245614035088"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_on_cross_val = np.count_nonzero(cross_val_class == boolean_mask_predicted_cross)/cross_val_class.shape[0]\n",
    "accuracy_on_cross_val\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so the accuracy of the algorihtm on cross validation data is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92.98245614035088"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Percent_accuracy_on_cross_val_data = accuracy_on_cross_val*100\n",
    "Percent_accuracy_on_cross_val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Training_data_class = Training_data[\"diagnosis\"]\n",
    "Training_data_class.replace(to_replace=[\"M\",\"B\"],value=[1,0],inplace=True)\n",
    "Training_data_class = np.array(Training_data_class)\n",
    "Training_data_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.99967136, 0.9999805 , 0.99651127, 0.99999929,\n",
       "       0.41355606, 0.99615996, 0.58706516, 0.99491244, 0.99628573,\n",
       "       0.84161638, 0.81122193, 1.        , 0.94304366, 0.99998849,\n",
       "       0.99726563, 0.27481866, 0.9998201 , 0.99993945, 0.03460896,\n",
       "       0.10810842, 0.0070763 , 0.99205567, 0.99998835, 0.99375691,\n",
       "       0.99999958, 0.99412632, 0.99858712, 0.99966332, 0.94809746,\n",
       "       0.9999998 , 0.19961126, 0.99939781, 0.99999866, 0.98837759,\n",
       "       0.98550238, 0.71127386, 0.0722918 , 0.81380271, 0.41551258,\n",
       "       0.16258702, 0.21512523, 0.99999999, 0.43733265, 0.19915826,\n",
       "       0.99989064, 0.02557259, 0.1513314 , 0.0202484 , 0.21175852,\n",
       "       0.08280562, 0.04770015, 0.03581319, 0.99908248, 0.51035466,\n",
       "       0.0309642 , 0.99838881, 0.47319392, 0.10329441, 0.00853292,\n",
       "       0.01029319, 0.0622907 , 0.99989884, 0.01427408, 0.36470254,\n",
       "       0.93830805, 0.05109131, 0.03367352, 0.04740852, 0.03068706,\n",
       "       0.99856843, 0.12270217, 0.99979539, 0.19324425, 0.02410168,\n",
       "       0.65184697, 0.03101829, 0.99988234, 1.        , 0.05501785,\n",
       "       0.06246948, 0.05123145, 1.        , 1.        , 0.01652832,\n",
       "       0.99684844, 0.45304164, 0.99934809, 0.11070157, 0.26336433,\n",
       "       0.59844997, 0.79228095, 0.02630148, 0.06947472, 0.98830393,\n",
       "       0.99996181, 0.02965596, 0.0364436 , 0.00849583, 0.51415181,\n",
       "       0.47611723, 0.02729123, 0.07848795, 0.04584578, 0.03178127,\n",
       "       0.70028518, 0.03430741, 0.03840717, 1.        , 0.05861879,\n",
       "       0.016951  , 0.13981879, 0.99999967, 0.09659765, 0.01792587,\n",
       "       0.07640331, 0.06715274, 0.91274174, 0.99977104, 0.98665564,\n",
       "       0.00660259, 0.98749489, 1.        , 0.06800825, 0.04191197,\n",
       "       0.07117688, 0.41957822, 0.99517778, 0.76364578, 0.9999925 ,\n",
       "       0.01903899, 0.8620292 , 0.95986049, 0.2616666 , 0.99626826,\n",
       "       0.14692517, 0.01865689, 0.01284352, 0.225034  , 0.01292689,\n",
       "       0.00752647, 0.71452508, 0.0233996 , 0.04421337, 0.01083892,\n",
       "       0.0707017 , 0.79347751, 0.54047681, 0.1320066 , 0.07333777,\n",
       "       0.10025001, 0.10812679, 0.04865279, 0.00794513, 0.04311111,\n",
       "       0.0312672 , 0.99974678, 0.80683443, 0.0095764 , 0.00953644,\n",
       "       0.06616774, 0.99939747, 0.99999915, 0.13688073, 0.99999998,\n",
       "       0.34266081, 0.00459218, 0.86372681, 0.99991562, 0.15950462,\n",
       "       0.00988229, 0.09673362, 0.90615041, 0.01145477, 0.01184983,\n",
       "       0.01427993, 0.05333192, 0.99710723, 0.30402038, 0.01691089,\n",
       "       1.        , 1.        , 0.54281713, 0.01393647, 0.63240443,\n",
       "       0.01143621, 0.9767923 , 0.02129651, 0.02339821, 0.01949401,\n",
       "       0.96490501, 0.10654668, 0.03911247, 0.79349888, 0.99995814,\n",
       "       0.02933089, 0.71288029, 0.98959906, 0.99999631, 0.48377107,\n",
       "       0.04872243, 0.98764029, 1.        , 0.94458781, 0.07463251,\n",
       "       0.39832412, 0.01745108, 0.87587026, 0.88180211, 0.0967198 ,\n",
       "       0.99998147, 0.0353768 , 1.        , 0.9986321 , 0.72197   ,\n",
       "       0.28712601, 0.05659183, 0.01804756, 0.99988739, 0.99999834,\n",
       "       0.02624063, 0.08480052, 0.01869525, 0.71038212, 0.04709125,\n",
       "       0.05016826, 0.01140127, 0.19114087, 0.22419591, 0.87438067,\n",
       "       0.99923577, 0.41630307, 0.96549487, 0.9999982 , 0.01574817,\n",
       "       0.22374072, 1.        , 0.99988326, 0.87890656, 0.99999577,\n",
       "       0.03946457, 0.0227661 , 0.07947969, 0.35501027, 0.999999  ,\n",
       "       0.03452913, 0.04927703, 0.1836051 , 0.18575647, 0.01234184,\n",
       "       0.99999993, 0.02792029, 0.99999165, 0.92876183, 0.99849624,\n",
       "       0.24883335, 1.        , 0.9997658 , 1.        , 0.99998569,\n",
       "       0.99999467, 0.97703971, 0.99890286, 0.45219616, 0.95902333,\n",
       "       0.99999973, 0.07696149, 0.19181156, 0.02763645, 0.06542915,\n",
       "       0.17788647, 0.00801277, 1.        , 0.01358122, 0.99386516,\n",
       "       0.02347938, 0.0109797 , 0.99346563, 0.08970937, 0.04266632,\n",
       "       0.99998109, 0.01343744, 0.99940978, 0.99973782, 0.06485013,\n",
       "       0.05094424, 0.13152714, 0.0171593 , 0.12613745, 0.03303539,\n",
       "       0.97533381, 0.32531888, 0.02813768, 0.02410046, 0.01624449,\n",
       "       0.02743068, 0.00707857, 0.02765459, 0.12067846, 0.09506713,\n",
       "       0.99998812, 0.0673051 , 1.        , 0.02424236, 0.02617014,\n",
       "       0.17424338, 0.03401173, 0.01417657, 0.02577961, 0.02476022,\n",
       "       0.03844062, 0.13712909, 0.0171747 , 0.00590839, 0.03572502,\n",
       "       0.03342   , 0.01472676, 0.98541774, 0.34666203, 0.03879097,\n",
       "       0.02428334, 0.99969588, 0.0169347 , 0.99999998, 0.01592847,\n",
       "       0.03237141, 0.03536343, 0.03882324, 0.95426366, 0.99169186,\n",
       "       0.91940481, 0.12703854, 0.03835463, 0.01172233, 0.05757515,\n",
       "       0.97865328, 0.0273552 , 0.99891411, 0.0194565 , 1.        ,\n",
       "       0.22604497, 0.01820431, 0.01538151, 0.99998101, 0.01427706,\n",
       "       0.01319078, 0.04146576, 0.08316819, 0.01532057, 0.01841634,\n",
       "       0.02679409, 0.99999926, 1.        , 0.86189304, 0.00933563,\n",
       "       0.11166382, 0.12416289, 0.05768173, 0.01538296, 0.02455657,\n",
       "       0.05028726, 0.14927677, 0.05068153, 0.66033402, 0.04889462,\n",
       "       0.99997161, 0.99999967, 0.03147333, 0.99998105, 1.        ,\n",
       "       0.99961382, 0.09402068, 0.99999923, 0.9998947 , 0.04549973,\n",
       "       0.86269044, 0.44046664, 0.76678586, 0.0445778 , 0.28791424,\n",
       "       0.01494473, 0.01099245, 0.26233239, 0.0597975 , 0.02631142,\n",
       "       0.49324685, 0.01573399, 0.06293935, 0.02918573, 0.99997839,\n",
       "       0.00686038, 0.02044348, 0.95613337, 1.        , 0.03267716,\n",
       "       0.0846202 , 0.1744222 , 0.05650517])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_training = predicated_category(Training_data.iloc[:,1:])\n",
    "predicted_training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1,\n",
       "       1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0], dtype=uint32)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_training_values = predicted_training>0.5   #if >0.5 then trure else false\n",
    "predicted_training_values = np.uint(predicted_training_values)\n",
    "predicted_training_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comparing values of predicted values for training class vs actual values\n",
    "Training_data_accuracy = np.count_nonzero(Training_data_class== predicted_training_values)/Training_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90.45226130653266"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#calculating accuracy on training data\n",
    "Training_data_accuracy*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets see the accuracy on testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1,\n",
       "       1, 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_data_class = Testing_data[\"diagnosis\"]\n",
    "Testing_data_class.replace(to_replace=[\"M\",\"B\"],value=[1,0],inplace=True)\n",
    "Testing_data_class = np.array(Testing_data_class)\n",
    "Testing_data_class #actual class values in testing data in binomial form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.90093194, 0.63184849, 0.44614642, 0.41884816, 0.48244398,\n",
       "       0.99466977, 1.        , 0.79323854, 0.02835383, 0.05458347,\n",
       "       0.34381799, 0.28806746, 0.02423412, 0.99999996, 0.14327417,\n",
       "       0.02428539, 0.55134459, 0.11778196, 0.86972542, 0.01836202,\n",
       "       0.0303393 , 0.32109018, 0.06112004, 0.01290829, 0.99999493,\n",
       "       0.03343243, 0.1264415 , 0.03903775, 0.06688686, 0.35095715,\n",
       "       0.62127735, 0.11867649, 0.99987495, 0.02187417, 0.81699025,\n",
       "       0.11811621, 0.81042676, 0.99744854, 0.01515754, 0.10645086,\n",
       "       0.33320661, 0.11776377, 0.0341627 , 0.99617998, 1.        ,\n",
       "       0.56692647, 0.99319702, 0.03534722, 0.99999999, 0.13654156,\n",
       "       0.12241311, 0.09687703, 0.0207675 , 0.40704752, 0.99987444,\n",
       "       0.02433763, 0.09102474, 0.72810953, 0.07133026, 0.29727843,\n",
       "       0.02821065, 0.99942397, 0.999903  , 0.18516239, 0.0393096 ,\n",
       "       0.01354241, 1.        , 0.04544955, 0.10984939, 0.01275437,\n",
       "       0.01062412, 0.12046172, 0.00975022, 0.04430002, 0.01300521,\n",
       "       0.02945395, 0.0499317 , 0.04790557, 0.99998975, 0.02575353,\n",
       "       1.        , 0.76819439, 0.34963746, 0.43291413, 0.34071941,\n",
       "       0.01580283, 0.97618053, 0.72249897, 0.68348007, 0.20144445,\n",
       "       0.29103439, 0.01508212, 0.01590254, 0.03562854, 0.1408976 ,\n",
       "       0.07847566, 0.08367692, 0.79007622, 0.07357641, 0.72611646,\n",
       "       0.37525572, 0.03150251, 0.49668071, 0.93037223, 0.1800239 ,\n",
       "       0.81345946, 0.72039623, 0.99999987, 1.        , 0.99999972,\n",
       "       0.99999129, 0.99419063, 1.        , 0.40052482])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_data_predicted = predicated_category(Testing_data.iloc[:,1:])\n",
    "Testing_data_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_data_predicted_bool = Testing_data_predicted>0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0], dtype=uint32)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_data_predicted_bool = np.uint(Testing_data_predicted_bool)\n",
    "Testing_data_predicted_bool   #predicted values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testing_data_accuracy = np.count_nonzero(Testing_data_predicted_bool == Testing_data_class)/Testing_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8508771929824561"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Testing_data_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SUMMARY OF HOW TO PERFORM NAIVE BAYES OR DEAL WITH THE FORMULA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
